runApp('Documents/Work/MEI/DiSARM/GitRepos/NTD_wireframe')
runApp('Documents/Work/MEI/DiSARM/GitRepos/NTD_wireframe')
runApp('Documents/Work/MEI/DiSARM/GitRepos/NTD_wireframe')
runApp('Documents/Work/MEI/DiSARM/GitRepos/NTD_wireframe')
shiny::runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-rate-density')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-rate-density')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
# Load demo data
load("UV_USA_airports.RData") # object called input
getwd()
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-rate-density')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-rate-density')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-rate-density')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
?box-orient
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
?column
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
?strong
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-spatial-prediction')
runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-tz-bldg-ui')
shiny::runApp('Documents/Work/MEI/DiSARM/GitRepos/demo-rate-density')
shiny::runApp('Documents/Work/MEI/DiSARM/GitRepos/NTD_wireframe')
## Map malaria vector data
read.csv("/Users/hughsturrock/Downloads/Anopheline_data.csv")
## Map malaria vector data
vec_data <- read.csv("/Users/hughsturrock/Downloads/Anopheline_data.csv")
library(leaflet)
leafet() %>% addTiles() %>%
addCircleMarkers(vec_data$longitude, vec_data$latitude)
leaflet() %>% addTiles() %>%
addCircleMarkers(vec_data$longitude, vec_data$latitude)
leaflet() %>% addTiles() %>%
addCircleMarkers(vec_data$longitude, vec_data$latitude, radius=1, weight=1)
runApp('Documents/Work/MEI/DiSARM/GitRepos/NTD_wireframe')
shiny::runApp('Documents/Work/MEI/DiSARM/GitRepos/NTD_wireframe')
runApp('Documents/Work/MEI/DiSARM/GitRepos/NTD_wireframe')
request
length(request)
response <- httr::content(request, as='text')
response
length(response)
request[1]
request[1]
request[2]
request[3]
request[4]
request[5]
request[6]
request[7]
request[8]
request[9]
request[3]
request[1]
request[2]
runApp('Documents/Work/MEI/DiSARM/GitRepos/NTD_wireframe')
runApp('Documents/Work/MEI/DiSARM/GitRepos/NTD_wireframe')
setwd("/Users/hughsturrock/Documents/Work/MEI/DiSARM/GitRepos/spatial-epi-course/course_materials/week3/Lab_files")
# Load relevant libraries
library(spatstat)
library(raster)
library(sp)
library(lgcp)
library(geoR)
library(gtools)
library(lme4)
library(leaflet)
library(oro.nifti)
CaseControl<-read.csv("CaseControl.csv")
Cases<-CaseControl[CaseControl$case==1,]
Controls<-CaseControl[CaseControl$case==0,]
# And boundary file
NAM_Adm0<-raster::getData('GADM',country='NAM',level=0)
# Convert to a SPDF
CaseControl_SPDF <- SpatialPointsDataFrame(coords = CaseControl[,c("long", "lat")],
data = CaseControl[,c("household_id", "case")])
# Let's plot and see what we have
case_color_scheme <- colorNumeric(c("blue", "red"), CaseControl_SPDF$case)
# Interpolation of point (prevalence etc.) data
# Open BF malaria data
BF_malaria_data <- read.csv("BF_malaria_data.csv",
header=T)
BF_Adm_1 <- raster::getData("GADM", country="BFA", level=1)
# Calc prevalence
BF_malaria_data$prevalence <- BF_malaria_data$positives / BF_malaria_data$examined
# Inverse distance weighting
BF_malaria_window<-owin(xrange=range(BF_malaria_data$longitude),yrange=range(BF_malaria_data$latitude))
BF_malaria_data_ppp<-ppp(BF_malaria_data$longitude,BF_malaria_data$latitude,
marks=BF_malaria_data$prevalence,window=BF_malaria_window)
par(mfrow=c(2,2))
plot(idw(BF_malaria_data_ppp, power=0.2, at="pixels"),col=heat.colors(20), main="power = 0.2")
plot(idw(BF_malaria_data_ppp, power=0.5, at="pixels"),col=heat.colors(20), main="power = 0.5")
plot(idw(BF_malaria_data_ppp, power=1, at="pixels"),col=heat.colors(20), main="power = 0.1")
plot(idw(BF_malaria_data_ppp, power=2, at="pixels"),col=heat.colors(20), main="power = 2") # Larger power puts more weight on nearer values
# Plot using leaflet
BF_malaria_prev_idw_raster <- raster(idw(BF_malaria_data_ppp, power=0.2, at="pixels"),
crs= crs(BF_Adm_1))
colPal <- colorNumeric(tim.colors(), BF_malaria_prev_idw_raster[], na.color = NA)
leaflet() %>% addTiles() %>% addRasterImage(BF_malaria_prev_idw_raster, col = colPal, opacity=0.7) %>%
addLegend(pal = colPal, values = BF_malaria_prev_idw_raster[])
# To calculate the 'best' power to use, you can use cross-validation.
CV_idw_1<-idw(BF_malaria_data_ppp, power=1, at="points")
plot(BF_malaria_data_ppp$marks, CV_idw_1, asp=1) # Not very good!
# Calc MSE
library(Metrics)
mse(BF_malaria_data_ppp$marks,CV_idw_1) # Mean squared error
# Kriging
# Before Kriging, good to transform prevalence
# data to something vaguely normal
# Here we use the logistic transformation (log odds)
BF_malaria_data$log_odds <- logit(BF_malaria_data$prevalence)
hist(BF_malaria_data$log_odds)
# First have to create a geodata object with the package GeoR
# this wants dataframe of x,y and data
BF_malaria_data_geo<-as.geodata(BF_malaria_data[,c("longitude","latitude","log_odds")])
# We can plot a summary plot
plot(BF_malaria_data_geo, lowes=T) # the lowes option gives us lowes curves for relationship with x and y
plot(BF_malaria_data_geo, lowes=T,trend="2nd") # Trend option regresses on x and y
# Now generate and plot a variogram
MaxDist=max(dist(BF_malaria_data[,c("longitude","latitude")]))  /2 # the max distance you should estimate is half max interpoint distance
VarioCloud<-variog(BF_malaria_data_geo,option="cloud",max.dist=MaxDist)
plot(VarioCloud) # all pairwise comparisons
# To produce binned variogram
Vario<-variog(BF_malaria_data_geo, max.dist = MaxDist)
plot(Vario)
Vario<-variog(BF_malaria_data_geo,max.dist=MaxDist,uvec=seq(0.01,MaxDist,0.2
))
Vario$n # Shows you the number in each bin
min(Vario$n)# should be at least 30 pairs in each bin
plot(Vario,pch=16)
Vario<-variog(BF_malaria_data_geo,max.dist=MaxDist,uvec=seq(0.01,MaxDist,0.3
))
Vario$n # Shows you the number in each bin
min(Vario$n)# should be at least 30 pairs in each bin
plot(Vario,pch=16)
# Fit variogram model by minimized least sqaures
VarioMod_lin<-variofit(VarioCloud, cov.model = "linear")
Vario<-variog(BF_malaria_data_geo,max.dist=MaxDist,uvec=seq(0.01,MaxDist,0.35))
Vario$n # Shows you the number in each bin
min(Vario$n)# should be at least 30 pairs in each bin
plot(Vario,pch=16)
# Fit variogram model by minimized least sqaures
VarioMod_lin<-variofit(VarioCloud, cov.model = "linear")
VarioMod_sph<-variofit(VarioCloud, cov.model = "sph")
VarioMod_exp<-variofit(VarioCloud, cov.model = "exp")
# plot results
lines(VarioMod_lin,col="green",lwd=2)
lines(VarioMod_sph,col="blue",lwd=2)
lines(VarioMod_exp,col="red",lwd=2) # In this example, all models converge on essentially the same line
max(dist(BF_malaria_data[,c("longitude","latitude")]))  /2
VarioCloud<-variog(BF_malaria_data_geo,option="cloud",max.dist=3)
Vario<-variog(BF_malaria_data_geo,max.dist=MaxDist,uvec=seq(0.01,MaxDist,0.35))
Vario$n # Shows you the number in each bin
min(Vario$n)# should be at least 30 pairs in each bin
plot(Vario,pch=16)
MaxDist=3
Vario<-variog(BF_malaria_data_geo,max.dist=MaxDist,uvec=seq(0.01,MaxDist,0.35))
Vario$n # Shows you the number in each bin
min(Vario$n)# should be at least 30 pairs in each bin
plot(Vario,pch=16)
# Fit variogram model by minimized least sqaures
VarioMod_lin<-variofit(VarioCloud, cov.model = "linear")
VarioMod_sph<-variofit(VarioCloud, cov.model = "sph")
VarioMod_exp<-variofit(VarioCloud, cov.model = "exp")
# plot results
lines(VarioMod_lin,col="green",lwd=2)
lines(VarioMod_sph,col="blue",lwd=2)
lines(VarioMod_exp,col="red",lwd=2) # In this example, all models converge on essentially the same line
MaxDist=2
Vario<-variog(BF_malaria_data_geo,max.dist=MaxDist,uvec=seq(0.01,MaxDist,0.35))
Vario$n # Shows you the number in each bin
min(Vario$n)# should be at least 30 pairs in each bin
plot(Vario,pch=16)
# Fit variogram model by minimized least sqaures
VarioMod_lin<-variofit(VarioCloud, cov.model = "linear")
VarioMod_sph<-variofit(VarioCloud, cov.model = "sph")
VarioMod_exp<-variofit(VarioCloud, cov.model = "exp")
# plot results
lines(VarioMod_lin,col="green",lwd=2)
lines(VarioMod_sph,col="blue",lwd=2)
lines(VarioMod_exp,col="red",lwd=2) # In this example, all models converge on essentially the same line
Vario<-variog(BF_malaria_data_geo,max.dist=MaxDist,uvec=seq(0.01,MaxDist,0.1))
Vario$n # Shows you the number in each bin
min(Vario$n)# should be at least 30 pairs in each bin
plot(Vario,pch=16)
# Fit variogram model by minimized least sqaures
VarioMod_lin<-variofit(VarioCloud, cov.model = "linear")
VarioMod_sph<-variofit(VarioCloud, cov.model = "sph")
VarioMod_exp<-variofit(VarioCloud, cov.model = "exp")
# plot results
lines(VarioMod_lin,col="green",lwd=2)
lines(VarioMod_sph,col="blue",lwd=2)
lines(VarioMod_exp,col="red",lwd=2) # In this example, all models converge on essentially the same line
min(Vario$n)# should be at least 30 pairs in each bin
Vario<-variog(BF_malaria_data_geo,max.dist=MaxDist,uvec=seq(0.01,MaxDist,0.15))
Vario$n # Shows you the number in each bin
min(Vario$n)# should be at least 30 pairs in each bin
plot(Vario,pch=16)
Vario<-variog(BF_malaria_data_geo,max.dist=MaxDist,uvec=seq(0.01,MaxDist,0.12))
Vario$n # Shows you the number in each bin
min(Vario$n)# should be at least 30 pairs in each bin
plot(Vario,pch=16)
# Fit variogram model by minimized least sqaures
VarioMod_lin<-variofit(VarioCloud, cov.model = "linear")
VarioMod_sph<-variofit(VarioCloud, cov.model = "sph")
VarioMod_exp<-variofit(VarioCloud, cov.model = "exp")
# plot results
lines(VarioMod_lin,col="green",lwd=2)
lines(VarioMod_sph,col="blue",lwd=2)
lines(VarioMod_exp,col="red",lwd=2) # In this example, all models converge on essentially the same line
# Use variogram to Krig values at prediction locations
# First get grid of points from the IDW example for comparison
# could use the expand.grid function
IDW<-idw(BF_malaria_data_ppp, power=0.2, at="pixels")
pred_grid_x<-rep(IDW$xcol,length(IDW$yrow))
pred_grid_y<-sort(rep(IDW$yrow,length(IDW$xcol)))
pred_grid<-cbind(pred_grid_x,pred_grid_y)
KrigPred <- krige.conv(BF_malaria_data_geo, loc=pred_grid,
krige=krige.control(obj.model=VarioMod_lin))
# Visualize predictions
image(KrigPred,col=heat.colors(50))
# Back transform to prevalence
KrigPred_prev<-inv.logit(KrigPred$predict)
KrigPred_raster <- rasterFromXYZ(data.frame(x=pred_grid_x,
y=pred_grid_y,
z=KrigPred_prev))
plot(KrigPred_raster)
points(BF_malaria_data[,c("longitude","latitude")],
cex = BF_malaria_data$prevalence)
# Its straightforward to CV kriged predictions in geoR
xvalid_result <- xvalid(BF_malaria_data_geo, model = VarioMod_lin) # By default it xvalidates point by point
plot(xvalid_result$data,xvalid_result$predicted) # log odds scale
abline(0,1)
plot(xvalid_result$data,xvalid_result$predicted, asp=1) # log odds scale
abline(0,1)
rm(list=ls())
setwd("points_st")
setwd("/Users/hughsturrock/Documents/Work/MEI/DiSARM/GitRepos/spatial-epi-course/course_materials/week3/Lab_files")
library(sp)
library(raster)
library(leaflet)
library(oro.nifti)
library(rgdal)
library(geosphere)
##Subsetting Data
# Let's get admin 1 data for Burkina Faso
BF_Adm_1 <- readOGR(".", layer = "gadm36_BFA_1")
getwd()
setwd("/Users/hughsturrock/Documents/Work/MEI/DiSARM/GitRepos/spatial-epi-course/course_materials/week2/Lab_files")
##Subsetting Data
# Let's get admin 1 data for Burkina Faso
BF_Adm_1 <- readOGR(".", layer = "gadm36_BFA_1")
# You can subset a SpatialPolygonsDataFrame just like a data frame
#Let's subset the data first by row
BF_Adm_1_cropped <- BF_Adm_1[1,]
BF_Adm_1_cropped
#Plot the result
plot(BF_Adm_1)
lines(BF_Adm_1_cropped, col="red", lwd=2)
# You can also subset by name
BF_Adm_1_Cascades <- subset(BF_Adm_1, BF_Adm_1$NAME_1=="Cascades") #OR BF_Adm_1[BF_Adm_1$NAME_1=="Cascades",] will also work
BF_Adm_1_Cascades
#Plot the result
plot(BF_Adm_1)
lines(BF_Adm_1_Cascades, col="blue", lwd=2)
#Plot the result
plot(BF_Adm_1)
lines(BF_Adm_1_Cascades, col="blue", lwd=2)
## Projections
# Now read in the BF malaria data
# (This one has no covariates, we'll get these ourselves
BF_malaria_data <- read.csv("BF_malaria_data.csv",
header=T)
# Convert to a SPDF
BF_malaria_data_SPDF <- SpatialPointsDataFrame(coords = BF_malaria_data[,c("longitude", "latitude")],
data = BF_malaria_data[,c("examined", "positives")],
proj4string = CRS("+init=epsg:4326"))
# To identify the admin 1 unit each point lies within you can use the 'over' function
over(BF_malaria_data_SPDF, BF_Adm_1)
# The CRS isn't identical, so over kicks out an error.
crs(BF_Adm_1)
crs(BF_malaria_data_SPDF)
# To transform projections you can use the spTransform function
BF_malaria_data_SPDF <- spTransform(BF_malaria_data_SPDF, crs(BF_Adm_1))
BF_malaria_data_SPDF
# Now try again
BF_Adm_1_per_point <- over(BF_malaria_data_SPDF, BF_Adm_1)
##Data Calculations
# Now we can use this to calculate admin unit specific statistics
# We might be interested in the number of sites per admin unit
# We could just create a table
table(BF_Adm_1_per_point$NAME_1)
#Or we can use the tapply function for more complex calculations
#Let's look at the number examined per admin unit
Nex_per_Adm1 <- tapply(BF_malaria_data_SPDF$examined, BF_Adm_1_per_point$NAME_1, sum)
# Now let's get the number of positives by admin unit
Npos_per_Adm1 <- tapply(BF_malaria_data_SPDF$positives, BF_Adm_1_per_point$NAME_1, sum)
#Calculate the prevalence
prev_per_Adm1 <- Npos_per_Adm1 / Nex_per_Adm1
prev_per_Adm1
as.data.frame(prev_per_Adm1)
as.data.frame(prev_per_Adm1)[,1]
#Calculate the prevalence
prev_per_Adm1 <- data.frame(Npos_per_Adm1 / Nex_per_Adm1)
prev_per_Adm1
names(prev_per_Adm1)
#Calculate the prevalence
prev_per_Adm1 <- Npos_per_Adm1 / Nex_per_Adm1
names(prev_per_Adm1)
# You can now merge these prevalence estimates
# back into your SPDF. First convert your prev_per_Adm1
# vecotr into a dataframe with an ID column
prev_per_Adm1_df <- data.frame(NAME_1 = names(prev_per_Adm1),
prevalence = prev_per_Adm1)
prev_per_Adm1_df
# You can now merge these prevalence estimates
# back into your SPDF. First convert your prev_per_Adm1
# vecotr into a dataframe with an ID column
prev_per_Adm1_df <- data.frame(NAME_1 = names(prev_per_Adm1),
prevalence = prev_per_Adm1,
row.names=FALSE)
# You can now merge these prevalence estimates
# back into your SPDF. First convert your prev_per_Adm1
# vecotr into a dataframe with an ID column
prev_per_Adm1_df <- data.frame(NAME_1 = names(prev_per_Adm1),
prevalence = prev_per_Adm1,
row.names=NULL)
prev_per_Adm1_df
BF_malaria_data_SPDF <- merge(BF_malaria_data_SPDF, prev_per_Adm1_df,
by = "NAME_1")
head(prev_per_Adm1_df)
head(BF_malaria_data_SPDF)
BF_malaria_data_SPDF <- merge(BF_Adm_1, prev_per_Adm1_df,
by = "NAME_1")
head(BF_malaria_data_SPDF)
#Mapping Calculated Values
# Now we can use this to make a map of prevalence
#Assign a color pallete to the quantiles
colorPal <- colorQuantile(tim.colors(), BF_malaria_data_SPDF$prevalence, n = 4)
#Plot
plot(BF_Adm_1, col=colorPal(BF_malaria_data_SPDF$prevalence))
#...Or
leaflet() %>% addTiles() %>% addPolygons(data=BF_Adm_1,
col=colorPal(BF_malaria_data_SPDF$prevalence),
fillOpacity=0.6)
#You can also define your own color bins
colorPal <- colorBin(tim.colors(), prev_per_Adm1, bins = c(0, 0.25, 0.5, 0.75, 1))
#Plot
plot(BF_Adm_1, col=colorPal(prev_per_Adm1))
# Elevation
BF_elev <- raster::getData("alt", country="BF")
BF_elev <- raster("")
plot(BF_elev)
# Land use (# For information on land use classifications see http://due.esrin.esa.int/files/GLOBCOVER2009_Validation_Report_2.2.pdf)
BF_land_use <- raster("BF_land_use.tif")
BF_land_use
#Plot the land use raster
plot(BF_land_use)
str(BF_land_use)
# For a break down of the classes in BF aka how often each land use type occurs in BF
table(BF_land_use[])
##Resampling Raster Files (see lecture video for more)
# Its good practice to resample rasters to the
# same extent and resolution (i.e. same grid)
# This makes it easier to deal with later and to relate rasters to each other
# The resample command makes this process easy
# The default method is bilinear interpolation,
# which doesn't make sense for our categorical
# variable, so we can use the nearest neighbour function 'ngb
BF_land_use_resampled <- resample(BF_land_use, BF_elev, method="ngb")
# AH - why might they not intercect?? Hint: check the projections...
crs(BF_land_use) # Mercator
crs(BF_elev) # WGS84
# To reproject a raster, you can use the projectRaster function
BF_land_use <- projectRaster(BF_land_use, crs=crs(BF_elev), method="ngb")
# Now try resampling
BF_land_use_resampled <- resample(BF_land_use, BF_elev, method="ngb")
BF_land_use_resampled;BF_elev
##Manipulating Raster Data
#1.You might want to change the resolution for analysis
#First, let's check the resolution
res(BF_elev) # in decimal degrees. 1 dd roughly 111km at the equator
#Let's change it
BF_elev_low_res <- aggregate(BF_elev, fact = 10) # by default, calculates mean
res(BF_elev_low_res)
plot(BF_elev_low_res)
#2.You can crop the raster to another spatial layer
BF_elev_Cascades <- crop(BF_elev, BF_Adm_1_Cascades)
plot(BF_elev_Cascades)
lines(BF_Adm_1_Cascades)
#3.You can change the values of tthe pixels
plot(BF_elev*3.28) # in feet
# to recategorize
plot(cut(BF_elev, 4))
#or create a new raster and change its values
BF_elev_cat <- BF_elev
BF_elev_cat[] <- ifelse(BF_elev[]>250,1,2)
plot(BF_elev_cat)
# If a raster is the same resolution and extent, you can perform joint operations on them, e.g.
plot(BF_elev - BF_land_use_resampled) # Meaningless! Just for illustrative purposes..
##Extracting Data From Raster Files
# Now let's extract values of elevation at each survey point
# you can use the extract function from the raster package
extract(BF_elev, BF_malaria_data_SPDF)
BF_malaria_data_SPDF
BF_Adm_1 <- merge(BF_Adm_1, prev_per_Adm1_df,
by = "NAME_1")
head(BF_Adm_1)
#Mapping Calculated Values
# Now we can use this to make a map of prevalence
#Assign a color pallete to the quantiles
colorPal <- colorQuantile(tim.colors(), BF_Adm_1$prevalence, n = 4)
#Plot
plot(BF_Adm_1, col=colorPal(BF_Adm_1$prevalence))
#...Or
leaflet() %>% addTiles() %>% addPolygons(data=BF_Adm_1,
col=colorPal(BF_Adm_1$prevalence),
fillOpacity=0.6)
#You can also define your own color bins
colorPal <- colorBin(tim.colors(), BF_Adm_1$prevalence, bins = c(0, 0.25, 0.5, 0.75, 1))
#Plot
plot(BF_Adm_1, col=colorPal(BF_Adm_1$prevalence))
# Elevation
BF_elev <- raster::getData("alt", country="BF")
BF_malaria_data_SPDF <- SpatialPointsDataFrame(coords = BF_malaria_data[,c("longitude", "latitude")],
data = BF_malaria_data[,c("examined", "positives")],
proj4string = CRS("+init=epsg:4326"))
# To identify the admin 1 unit each point lies within you can use the 'over' function
over(BF_malaria_data_SPDF, BF_Adm_1)
# The CRS isn't identical, so over kicks out an error.
crs(BF_Adm_1)
crs(BF_malaria_data_SPDF)
# To transform projections you can use the spTransform function
BF_malaria_data_SPDF <- spTransform(BF_malaria_data_SPDF, crs(BF_Adm_1))
BF_malaria_data_SPDF
# Now try again
BF_Adm_1_per_point <- over(BF_malaria_data_SPDF, BF_Adm_1)
##Data Calculations
# Now we can use this to calculate admin unit specific statistics
# We might be interested in the number of sites per admin unit
# We could just create a table
table(BF_Adm_1_per_point$NAME_1)
#Or we can use the tapply function for more complex calculations
#Let's look at the number examined per admin unit
Nex_per_Adm1 <- tapply(BF_malaria_data_SPDF$examined, BF_Adm_1_per_point$NAME_1, sum)
# Now let's get the number of positives by admin unit
Npos_per_Adm1 <- tapply(BF_malaria_data_SPDF$positives, BF_Adm_1_per_point$NAME_1, sum)
#Calculate the prevalence
prev_per_Adm1 <- Npos_per_Adm1 / Nex_per_Adm1
BF_malaria_data_SPDF
# We can catch this as an object, or add it directly to our SPDF
BF_malaria_data_SPDF$elev <- extract(BF_elev, BF_malaria_data_SPDF)
BF_malaria_data_SPDF# now has 3 variables
#Spatial Data Analysis
# We can now have a quick look at the relationship between prevalence and elevation
# First generate a prevalence variable
BF_malaria_data_SPDF$prevalence <- BF_malaria_data_SPDF$positives / BF_malaria_data_SPDF$examined
plot(BF_malaria_data_SPDF$elev, BF_malaria_data_SPDF$prevalence)
# Can you change the x and y axis labels so they are cleaner?
library(stats)
scatter.smooth(BF_malaria_data_SPDF$elev, BF_malaria_data_SPDF$prevalence) # with lowes
# You can also extract values using polygons e.g to get admin 1 level elevations
# You just have to define a function to apply, otherwise you get all the pixel values per polygon
BF_Adm_1$elev <- extract(BF_elev, BF_Adm_1, fun=mean, na.rm=TRUE) # takes a little longer..
# You might also be interested in distances to/from other features (e.g. health facilities, water)
# e.g. distance to nearest river
# Get a rivers file (obtained via http://www.diva-gis.org/Data)
waterbodies <- readOGR("BFA_waterbody_shapefile", "BFA_water_areas_dcw")
waterbodies
# What is the projection of this shapefile?
plot(waterbodies)
# The goesphere package has some nice functions such as (takes a little while to compute)
dist_to_water <- dist2Line(BF_malaria_data_SPDF, waterbodies)
# Look at the result
dist_to_water
# Can add to your data frame
BF_malaria_data_SPDF$dist_to_water <- dist_to_water[,1]
# If the objects you are interested in calucating distance
# to are points as opposed to polygons/lines (as above)
# you first have to calculate the distance to every
# point and then identify the minimum
# For example, imagine waterbodies data was only available
# as a point dataset (we can fake this by calculating the
# centroid of each polygon)
waterbodies_points <- gCentroid(waterbodies, byid=TRUE)
library(rgeos)
# If the objects you are interested in calucating distance
# to are points as opposed to polygons/lines (as above)
# you first have to calculate the distance to every
# point and then identify the minimum
# For example, imagine waterbodies data was only available
# as a point dataset (we can fake this by calculating the
# centroid of each polygon)
waterbodies_points <- gCentroid(waterbodies, byid=TRUE)
# Now calucate a distance matrix showing distances
# between each observation and each waterbody point
dist_matrix <- distm(BF_malaria_data_SPDF, waterbodies_points)
# Then use the apply function to apply the 'minimum'
# function to each row (as each row represents the distance of
# every waterbody point from our first observation)
BF_malaria_data_SPDF$dist_to_water_point <- apply(dist_matrix, 1, min)
BF_malaria_data_SPDF$dist_to_water_point
getwd()
